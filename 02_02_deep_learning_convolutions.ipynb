{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcfYNavBSDFOLVIcX055pT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satani99/generative_deep_learning/blob/main/02_02_deep_learning_convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4LgjEgiBPpJr"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch \n",
        "import torch.nn.functional as F\n",
        "\n",
        "convlayer1 = nn.Conv2d(1, 2, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Conv, self).__init__()\n",
        "\n",
        "    self.conv_layer_1 = nn.Conv2d(3, 10, kernel_size=4, stride=2)\n",
        "    self.conv_layer_2 = nn.Conv2d(10, 20, kernel_size=3, stride=2)  \n",
        "    self.linear = nn.Linear(980, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_layer_1(x)\n",
        "    x = self.conv_layer_2(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    output = F.softmax(self.linear(x))\n",
        "    return output"
      ],
      "metadata": {
        "id": "RUGUwss6PzE-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Conv()\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zspeRiSgYR8Z",
        "outputId": "67c69354-b200-4257-fa3a-92194287024f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv(\n",
            "  (conv_layer_1): Conv2d(3, 10, kernel_size=(4, 4), stride=(2, 2))\n",
            "  (conv_layer_2): Conv2d(10, 20, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (linear): Linear(in_features=980, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1)\n",
        "    self.conv1_bn = nn.BatchNorm2d(32)\n",
        "    self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2)\n",
        "    self.conv2_bn = nn.BatchNorm2d(32)\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
        "    self.conv3_bn = nn.BatchNorm2d(64)\n",
        "    self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=2)\n",
        "    self.conv4_bn = nn.BatchNorm2d(64)\n",
        "    self.linear1 = nn.Linear(1600, 128)\n",
        "    self.linear1_bn = nn.BatchNorm1d(num_features=128)\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.linear2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.leaky_relu(self.conv1_bn(x))\n",
        "    x = F.leaky_relu(self.conv2_bn(self.conv2(x)))\n",
        "    x = F.leaky_relu(self.conv3_bn(self.conv3(x)))\n",
        "    x = F.leaky_relu(self.conv4_bn(self.conv4(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.leaky_relu(self.linear1_bn(self.linear1(x)))\n",
        "    x = self.dropout(x)\n",
        "    output = F.softmax(self.linear2(x))\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "rM1Pnq9jYVV-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZCFeTzHM72v",
        "outputId": "ba83b86b-4aca-4ae0-d80a-2bd3bf24b975"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (conv2_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (conv4_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (linear1): Linear(in_features=1600, out_features=128, bias=True)\n",
            "  (linear1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (linear2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.nn.functional import one_hot\n",
        "import torchvision\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./content', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./content', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sRdazreNP2Q",
        "outputId": "aea8e6bf-a448-45a6-c514-6bc25339913f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j, data in enumerate(trainloader, 0):\n",
        "  inputs, labels = data\n",
        "  print(inputs.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfMFnYWhR4Wa",
        "outputId": "26189035-b465-4e29-a503-21d56b611df0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "final_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  epoch_loss = 0.0\n",
        "  running_loss = 0.0\n",
        "  \n",
        "  for j, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    # final_losses.append(loss)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += outputs.shape[0] * loss.item()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if j % 1000 == 999:\n",
        "      print('[%d, %5d] loss: %.3f' % (i + 1, j+1, running_loss/1000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "  print(i+1, epoch_loss / len(trainset))\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuYAdjeBOtZY",
        "outputId": "aeb5a56e-be10-41b5-fd89-2e99f7523546"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  1000] loss: 2.087\n",
            "[1,  2000] loss: 2.093\n",
            "[1,  3000] loss: 2.073\n",
            "[1,  4000] loss: 2.068\n",
            "[1,  5000] loss: 2.067\n",
            "[1,  6000] loss: 2.059\n",
            "[1,  7000] loss: 2.054\n",
            "[1,  8000] loss: 2.055\n",
            "[1,  9000] loss: 2.042\n",
            "[1, 10000] loss: 2.033\n",
            "[1, 11000] loss: 2.044\n",
            "[1, 12000] loss: 2.029\n",
            "1 2.057800398015976\n",
            "[2,  1000] loss: 2.017\n",
            "[2,  2000] loss: 2.019\n",
            "[2,  3000] loss: 2.022\n",
            "[2,  4000] loss: 2.022\n",
            "[2,  5000] loss: 2.015\n",
            "[2,  6000] loss: 1.999\n",
            "[2,  7000] loss: 1.999\n",
            "[2,  8000] loss: 2.000\n",
            "[2,  9000] loss: 2.001\n",
            "[2, 10000] loss: 1.987\n",
            "[2, 11000] loss: 1.996\n",
            "[2, 12000] loss: 1.999\n",
            "2 2.005582045955658\n",
            "[3,  1000] loss: 1.980\n",
            "[3,  2000] loss: 1.976\n",
            "[3,  3000] loss: 1.973\n",
            "[3,  4000] loss: 1.981\n",
            "[3,  5000] loss: 1.988\n",
            "[3,  6000] loss: 1.971\n",
            "[3,  7000] loss: 1.966\n",
            "[3,  8000] loss: 1.976\n",
            "[3,  9000] loss: 1.984\n",
            "[3, 10000] loss: 1.957\n",
            "[3, 11000] loss: 1.972\n",
            "[3, 12000] loss: 1.960\n",
            "3 1.9726641983413695\n",
            "[4,  1000] loss: 1.954\n",
            "[4,  2000] loss: 1.955\n",
            "[4,  3000] loss: 1.949\n",
            "[4,  4000] loss: 1.955\n",
            "[4,  5000] loss: 1.957\n",
            "[4,  6000] loss: 1.949\n",
            "[4,  7000] loss: 1.956\n",
            "[4,  8000] loss: 1.945\n",
            "[4,  9000] loss: 1.947\n",
            "[4, 10000] loss: 1.946\n",
            "[4, 11000] loss: 1.948\n",
            "[4, 12000] loss: 1.942\n",
            "4 1.9500070047950744\n",
            "[5,  1000] loss: 1.948\n",
            "[5,  2000] loss: 1.928\n",
            "[5,  3000] loss: 1.922\n",
            "[5,  4000] loss: 1.929\n",
            "[5,  5000] loss: 1.945\n",
            "[5,  6000] loss: 1.936\n",
            "[5,  7000] loss: 1.921\n",
            "[5,  8000] loss: 1.931\n",
            "[5,  9000] loss: 1.939\n",
            "[5, 10000] loss: 1.923\n",
            "[5, 11000] loss: 1.930\n",
            "[5, 12000] loss: 1.927\n",
            "5 1.9306213834190369\n",
            "[6,  1000] loss: 1.921\n",
            "[6,  2000] loss: 1.924\n",
            "[6,  3000] loss: 1.926\n",
            "[6,  4000] loss: 1.918\n",
            "[6,  5000] loss: 1.927\n",
            "[6,  6000] loss: 1.918\n",
            "[6,  7000] loss: 1.920\n",
            "[6,  8000] loss: 1.918\n",
            "[6,  9000] loss: 1.925\n",
            "[6, 10000] loss: 1.919\n",
            "[6, 11000] loss: 1.928\n",
            "[6, 12000] loss: 1.929\n",
            "6 1.9229655894088744\n",
            "[7,  1000] loss: 1.908\n",
            "[7,  2000] loss: 1.930\n",
            "[7,  3000] loss: 1.912\n",
            "[7,  4000] loss: 1.903\n",
            "[7,  5000] loss: 1.915\n",
            "[7,  6000] loss: 1.911\n",
            "[7,  7000] loss: 1.909\n",
            "[7,  8000] loss: 1.905\n",
            "[7,  9000] loss: 1.917\n",
            "[7, 10000] loss: 1.907\n",
            "[7, 11000] loss: 1.900\n",
            "[7, 12000] loss: 1.906\n",
            "7 1.9100961773872376\n",
            "[8,  1000] loss: 1.895\n",
            "[8,  2000] loss: 1.908\n",
            "[8,  3000] loss: 1.906\n",
            "[8,  4000] loss: 1.898\n",
            "[8,  5000] loss: 1.896\n",
            "[8,  6000] loss: 1.890\n",
            "[8,  7000] loss: 1.891\n",
            "[8,  8000] loss: 1.900\n",
            "[8,  9000] loss: 1.906\n",
            "[8, 10000] loss: 1.915\n",
            "[8, 11000] loss: 1.905\n",
            "[8, 12000] loss: 1.887\n",
            "8 1.899433246421814\n",
            "[9,  1000] loss: 1.888\n",
            "[9,  2000] loss: 1.898\n",
            "[9,  3000] loss: 1.891\n",
            "[9,  4000] loss: 1.889\n",
            "[9,  5000] loss: 1.909\n",
            "[9,  6000] loss: 1.877\n",
            "[9,  7000] loss: 1.891\n",
            "[9,  8000] loss: 1.887\n",
            "[9,  9000] loss: 1.875\n",
            "[9, 10000] loss: 1.901\n",
            "[9, 11000] loss: 1.879\n",
            "[9, 12000] loss: 1.890\n",
            "9 1.8894342023658752\n",
            "[10,  1000] loss: 1.880\n",
            "[10,  2000] loss: 1.882\n",
            "[10,  3000] loss: 1.890\n",
            "[10,  4000] loss: 1.902\n",
            "[10,  5000] loss: 1.890\n",
            "[10,  6000] loss: 1.892\n",
            "[10,  7000] loss: 1.886\n",
            "[10,  8000] loss: 1.888\n",
            "[10,  9000] loss: 1.881\n",
            "[10, 10000] loss: 1.888\n",
            "[10, 11000] loss: 1.896\n",
            "[10, 12000] loss: 1.885\n",
            "10 1.8882550492858887\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "zirRUYmwWNIa"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ConvNet()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU5PM0JzWN-M",
        "outputId": "3a57c1c7-8303-45d9-c377-248a8ba049a5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "jIktisa_WcIp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qrMm4dXWfN8",
        "outputId": "92110764-6e20-41f6-8cb8-5fa3776a1887"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt02Pc9DWi-G",
        "outputId": "a08cdbb8-f50b-4c1d-e387-8a603518a285"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:  truck ship  horse deer \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrfcwsTKWjnt",
        "outputId": "9c469c4d-af75-41af-c0a6-43a93fb5faa0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroundTruth:  truck ship  plane car  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in testloader: \n",
        "    images, labels = data \n",
        "    outputs = net(images) \n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1) \n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct // total} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTXrXM0fO2c5",
        "outputId": "4eb75abf-35b5-45b4-8d3d-748c1a54d63f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 55 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FR-pJKXLW_51"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}